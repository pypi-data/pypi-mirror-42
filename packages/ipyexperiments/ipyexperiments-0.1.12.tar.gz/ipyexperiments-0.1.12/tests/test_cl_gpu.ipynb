{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellLogger subsystem\n",
    "\n",
    "This test tests the CellLogger subsystem, accessible via `exp.cl` once one of the `IPyExperiments` subclasses has been initiated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test specifics\n",
    "\n",
    "Since we need to validate the the output, we have to capture it first. The way jupyter is setup, is that in once cell you set up a capture with `%%capture` magick and then in the next cell you can analyze it. That's why each test group has two cells, the first one doing the action to be tested and the following one doing the validatations.\n",
    "\n",
    "Moreover, the output of this test becomes confusing because the capture mechanism somehow messes things up which leads to re-running the `post_run_cell` callback of the CellLogger subsystem again - as a result you get a bogus output with 0's regardless of the code being run. It doesn't interfere with the testing, but it does interfere with things like `.data` which gets reset because of that, showing invalid information - therefore we can only test `.data` w/o capturing the cell's output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyexperiments import *\n",
    "from utils.text import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipyexperiments.cell_logger.CellLogger at 0x7fa046eb6c18>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.005\n",
      "･ CPU:         0       0     2146 MB |\n",
      "･ GPU:         0       0     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "#if 'exp' in locals(): exp.cl.stop() # helps debug\n",
    "exp1 = IPyExperimentsPytorch(exp_enable=False)\n",
    "exp1.cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.127\n",
      "･ CPU:         0       0     2275 MB |\n",
      "･ GPU:         0       0     3945 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "gpu1 = consume_gpu_ram_256mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.116\n",
      "| ･ CPU:       128       0     2275 MB |\n",
      "| ･ GPU:       256       0     3945 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.006\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:      -256     256     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_strings(output)\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=0, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=0, abs_tol=0)\n",
    "\n",
    "# cleanup\n",
    "del cpu1, gpu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume/release leading to positive peak numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.246\n",
      "･ CPU:         0       0     2275 MB |\n",
      "･ GPU:         0     256     3945 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test peak measurement\n",
    "# here we consume 256MB of RAM and release 128MB \n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_peak_memory_usage'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.235\n",
      "| ･ CPU:       128     128     2275 MB |\n",
      "| ･ GPU:       256     256     3945 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.006\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:      -256     256     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_peak_memory_usage\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=128, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=256, abs_tol=2)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .data accessor validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.263\n",
      "･ CPU:       128     128     2275 MB |\n",
      "･ GPU:       256     256     3945 MB |\n"
     ]
    }
   ],
   "source": [
    "# no capture! breaks .data since it re-runs the post_run_cell, again, resetting .data\n",
    "# here we consume 256MB of RAM and release 128MB - so that we can test peak measurement\n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB - so that we can test peak measurement\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "## Consume/Release Positive Peak\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_data_accessor'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134224187\n",
      "134232116\n",
      "268435456\n",
      "268435456\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.006\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:      -256     256     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_data_accessor\"\"\"\n",
    "cpu_mem   = exp1.cl.data.cpu\n",
    "gpu_mem   = exp1.cl.data.gpu\n",
    "time_data = exp1.cl.data.time\n",
    "check_match(consumed_reported=b2mb(cpu_mem.used_delta), peaked_reported=b2mb(cpu_mem.peaked_delta), \n",
    "            consumed_expected=128,                      peaked_expected=128,  abs_tol=1)\n",
    "check_match(consumed_reported=b2mb(gpu_mem.used_delta), peaked_reported=b2mb(gpu_mem.peaked_delta), \n",
    "            consumed_expected=256,                      peaked_expected=256, abs_tol=1)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_stop'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.051\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:         0       0     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_stop\"\"\"\n",
    "exp1.cl.stop()\n",
    "#check that no output appears after this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No captured output\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "assert output == \"\", \"there should be no output as logger has been stopped\"\n",
    "\n",
    "# cleanup\n",
    "del cpu1\n",
    "del exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals_unset(['exp10'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.032\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:         0       0     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# this one tests with the exp-system turned on, cl-system turned on\n",
    "# this is a pretty normal situation, considering that someone will be reloading the same cell\n",
    "# do not change this test!\n",
    "exp10 = IPyExperimentsPytorch(exp_enable=True, cl_enable=True)\n",
    "exp10 = IPyExperimentsPytorch(exp_enable=True, cl_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:  Used  Free  Total      Util\n",
      "| CPU:  2147  2557  31588 MB   6.80% \n",
      "| GPU:  3689  4430   8119 MB  45.43% \n",
      "| \n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:  Used  Free  Total      Util\n",
      "| CPU:  2147  2557  31588 MB   6.80% \n",
      "| GPU:  3689  4430   8119 MB  45.43% \n",
      "| \n",
      "| \n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.024\n",
      "| ･ CPU:         0       0     2147 MB |\n",
      "| ･ GPU:         0       0     3689 MB |\n",
      "| \n",
      "| IPyExperimentsPytorch: Finishing\n",
      "| \n",
      "| *** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "| \n",
      "| *** Experiment memory:\n",
      "| RAM:  Consumed     Reclaimed\n",
      "| CPU:       0       0 MB (100.00%)\n",
      "| GPU:       0       0 MB (100.00%)\n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:  Used  Free  Total      Util\n",
      "| CPU:  2147  2557  31588 MB   6.80% \n",
      "| GPU:  3689  4430   8119 MB  45.43% \n",
      "| \n",
      "| \n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.022\n",
      "| ･ CPU:         0       0     2147 MB |\n",
      "| ･ GPU:         0       0     3689 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.352\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:         0       0     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\"\n",
    "\n",
    "match = re.findall(r'started', output)\n",
    "assert len(match) == 2, f\"should have started twice, got {len(match)}\"\n",
    "\n",
    "match = re.findall(r'Finishing', output)\n",
    "assert len(match) == 1, f\"should have finished once, got {len(match)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.078\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:         0       0     3689 MB |\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.078\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:         0       0     3689 MB |\n",
      "\n",
      "IPyExperimentsPytorch: Finishing\n",
      "\n",
      "*** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "\n",
      "*** Newly defined local variables:"
     ]
    }
   ],
   "source": [
    "# cleanup\n",
    "del exp10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleted: match\n",
      "\n",
      "*** Experiment memory:\n",
      "RAM:  Consumed     Reclaimed\n",
      "CPU:       0       0 MB (100.00%)\n",
      "GPU:       0       0 MB (100.00%)\n",
      "\n",
      "*** Current state:\n",
      "RAM:  Used  Free  Total      Util\n",
      "CPU:  2147  2551  31588 MB   6.80% \n",
      "GPU:  3689  4430   8119 MB  45.43% \n",
      "\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.020\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:         0       0     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# this one tests with the exp-system turned off, cl-system turned on\n",
    "# this is a pretty normal situation, considering that someone will be reloading the same cell\n",
    "# do not change this test!\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False, cl_enable=True)\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False, cl_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.022\n",
      "| ･ CPU:         0       0     2147 MB |\n",
      "| ･ GPU:         0       0     3689 MB |\n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.010\n",
      "| ･ CPU:         0       0     2147 MB |\n",
      "| ･ GPU:         0       0     3689 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.000\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:         0       0     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.043\n",
      "･ CPU:         0       0     2147 MB |\n",
      "･ GPU:         0       0     3689 MB |\n"
     ]
    }
   ],
   "source": [
    "# cleanup\n",
    "del exp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript # prevent committing an unsaved notebook\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "323px",
    "left": "956px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
