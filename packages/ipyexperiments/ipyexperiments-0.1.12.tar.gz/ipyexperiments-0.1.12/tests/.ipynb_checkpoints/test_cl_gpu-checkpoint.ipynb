{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellLogger subsystem\n",
    "\n",
    "This test tests the CellLogger subsystem, accessible via `exp.cl` once one of the `IPyExperiments` subclasses has been initiated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test specifics\n",
    "\n",
    "Since we need to validate the the output, we have to capture it first. The way jupyter is setup, is that in once cell you set up a capture with `%%capture` magick and then in the next cell you can analyze it. That's why each test group has two cells, the first one doing the action to be tested and the following one doing the validatations.\n",
    "\n",
    "Moreover, the output of this test becomes confusing because the capture mechanism somehow messes things up which leads to re-running the `post_run_cell` callback of the CellLogger subsystem again - as a result you get a bogus output with 0's regardless of the code being run. It doesn't interfere with the testing, but it does interfere with things like `.data` which gets reset because of that, showing invalid information - therefore we can only test `.data` w/o capturing the cell's output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyexperiments import *\n",
    "from utils.text import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipyexperiments.cell_logger.CellLogger at 0x7fef11b98160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.007s\n",
      "･ CPU:         0       0     2153 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "#if 'exp' in locals(): exp.cl.stop() # helps debug\n",
    "exp1 = IPyExperimentsPytorch(exp_enable=False)\n",
    "exp1.cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.130s\n",
      "･ CPU:         0       0     2281 MB   |\n",
      "･ GPU:         0       0     2494 MB   |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "gpu1 = consume_gpu_ram_256mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.118s\n",
      "| ･ CPU:       128       0     2281 MB   |\n",
      "| ･ GPU:       256       0     2494 MB   |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.008s\n",
      "･ CPU:         0       0     2153 MB   |\n",
      "･ GPU:      -256     256     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_strings(output)\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=0, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=0, abs_tol=0)\n",
    "\n",
    "# cleanup\n",
    "del cpu1, gpu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume/release leading to positive peak numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.247s\n",
      "･ CPU:         0       0     2281 MB   |\n",
      "･ GPU:         0     256     2494 MB   |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test peak measurement\n",
    "# here we consume 256MB of RAM and release 128MB \n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_peak_memory_usage'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.235s\n",
      "| ･ CPU:       128     128     2281 MB   |\n",
      "| ･ GPU:       256     256     2494 MB   |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.006s\n",
      "･ CPU:         0       0     2153 MB   |\n",
      "･ GPU:      -256     256     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_peak_memory_usage\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=128, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=256, abs_tol=2)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .data accessor validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.275s\n",
      "･ CPU:       128     128     2281 MB   |\n",
      "･ GPU:       256     256     2494 MB   |\n"
     ]
    }
   ],
   "source": [
    "# no capture! breaks .data since it re-runs the post_run_cell, again, resetting .data\n",
    "# here we consume 256MB of RAM and release 128MB - so that we can test peak measurement\n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB - so that we can test peak measurement\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "## Consume/Release Positive Peak\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_data_accessor'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134224380\n",
      "134231852\n",
      "268435456\n",
      "268435456\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.007s\n",
      "･ CPU:         0       0     2153 MB   |\n",
      "･ GPU:      -256     256     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_data_accessor\"\"\"\n",
    "cpu_mem, gpu_mem, time_data = exp1.cl.data\n",
    "\n",
    "check_match(consumed_reported=b2mb(cpu_mem.used_delta), peaked_reported=b2mb(cpu_mem.peaked_delta), \n",
    "            consumed_expected=128,                      peaked_expected=128,  abs_tol=1)\n",
    "check_match(consumed_reported=b2mb(gpu_mem.used_delta), peaked_reported=b2mb(gpu_mem.peaked_delta), \n",
    "            consumed_expected=256,                      peaked_expected=256, abs_tol=1)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_stop'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_stop\"\"\"\n",
    "exp1.cl.stop()\n",
    "#check that no output appears after this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No captured output\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "assert output == \"\", \"there should be no output as logger has been stopped\"\n",
    "\n",
    "# cleanup\n",
    "del cpu1\n",
    "del exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'exp10' in locals(): del exp10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.021s\n",
      "･ CPU:         0       0     2153 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# testing on the CL side since this is where weakref to self.exp is tricky\n",
    "# this is not a normal usage situation, but emulates an edge case, which we want to not fail\n",
    "exp10 = IPyExperimentsPytorch(cl_enable=True)\n",
    "exp10 = IPyExperimentsPytorch(cl_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:  Used  Free  Total      Util\n",
      "| CPU:  2153  8351  31588 MB   6.82% \n",
      "| GPU:  2238  5881   8119 MB  27.56% \n",
      "| \n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:  Used  Free  Total      Util\n",
      "| CPU:  2153  8351  31588 MB   6.82% \n",
      "| GPU:  2238  5881   8119 MB  27.56% \n",
      "| \n",
      "| \n",
      "| IPyExperimentsPytorch: Finishing\n",
      "| \n",
      "| *** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "| \n",
      "| *** Experiment memory:\n",
      "| RAM:  Consumed     Reclaimed\n",
      "| CPU:       0       0 MB (100.00%)\n",
      "| GPU:       0       0 MB (100.00%)\n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:  Used  Free  Total      Util\n",
      "| CPU:  2153  8351  31588 MB   6.82% \n",
      "| GPU:  2238  5881   8119 MB  27.56% \n",
      "| \n",
      "| \n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.011s\n",
      "| ･ CPU:         0     128     2153 MB   |\n",
      "| ･ GPU:         0       0     2238 MB   |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.002s\n",
      "･ CPU:         0       0     2153 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\"\n",
    "\n",
    "match = re.findall(r'started', output)\n",
    "assert len(match) == 2, f\"should have started twice, got {len(match)}\"\n",
    "\n",
    "match = re.findall(r'Finishing', output)\n",
    "assert len(match) == 1, f\"should have finished once, got {len(match)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPyExperimentsPytorch: Finishing\n",
      "\n",
      "*** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "\n",
      "*** Newly defined local variables:\n",
      "Deleted: match\n",
      "\n",
      "*** Experiment memory:\n",
      "RAM:  Consumed     Reclaimed\n",
      "CPU:       0       0 MB (  0.00%)\n",
      "GPU:       0       0 MB (100.00%)\n",
      "\n",
      "*** Current state:\n",
      "RAM:  Used  Free  Total      Util\n",
      "CPU:  2153  8351  31588 MB   6.82% \n",
      "GPU:  2238  5881   8119 MB  27.56% \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cleanup\n",
    "del exp10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "weakly-referenced object no longer exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReferenceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme1/fast.ai-1/br/stas00/ipyexperiments/tests/ipyexperiments/cell_logger.py\u001b[0m in \u001b[0;36mpost_run_cell\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# don't run this if self.exp doesn't exist anymore (weakref)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"post_run_cell: 1 f{self.exp}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReferenceError\u001b[0m: weakly-referenced object no longer exists"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function CellLogger.post_run_cell at 0x7fef094a5510> (for post_run_cell):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stas/anaconda3/envs/fastai/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/stas/anaconda3/envs/fastai/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/nvme1/fast.ai-1/br/stas00/ipyexperiments/tests/ipyexperiments/cell_logger.py\", line 191, in peak_monitor_func\n",
      "    gpu_mem_used = self.exp.gpu_ram_used_fast(gpu_handle)\n",
      "ReferenceError: weakly-referenced object no longer exists\n",
      "\n"
     ]
    },
    {
     "ename": "ReferenceError",
     "evalue": "weakly-referenced object no longer exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReferenceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme1/fast.ai-1/br/stas00/ipyexperiments/tests/ipyexperiments/cell_logger.py\u001b[0m in \u001b[0;36mpost_run_cell\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# don't run this if self.exp doesn't exist anymore (weakref)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"post_run_cell: 1 f{self.exp}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReferenceError\u001b[0m: weakly-referenced object no longer exists"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.016s\n",
      "･ CPU:         0       0     2153 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# this is a pretty normal situation, considering that someone will be reloading the same cell\n",
    "# do not change this test!\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False)\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function CellLogger.pre_run_cell at 0x7fef094a5ea0> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "ReferenceError",
     "evalue": "weakly-referenced object no longer exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReferenceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme1/fast.ai-1/br/stas00/ipyexperiments/tests/ipyexperiments/cell_logger.py\u001b[0m in \u001b[0;36mpre_run_cell\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"pre_run_cell: 1 f{self.exp}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# start RAM tracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReferenceError\u001b[0m: weakly-referenced object no longer exists"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| Error in callback <function CellLogger.post_run_cell at 0x7fef094a5510> (for post_run_cell):\n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.003s\n",
      "| ･ CPU:         0       0     2153 MB   |\n",
      "| ･ GPU:         0       0     2238 MB   |\n",
      "| \n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "shouldn't fail on auto-destruction",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-447e40d84c75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m\"Error\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shouldn't fail on auto-destruction\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: shouldn't fail on auto-destruction"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function CellLogger.post_run_cell at 0x7fef094a5510> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "ReferenceError",
     "evalue": "weakly-referenced object no longer exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReferenceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme1/fast.ai-1/br/stas00/ipyexperiments/tests/ipyexperiments/cell_logger.py\u001b[0m in \u001b[0;36mpost_run_cell\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# don't run this if self.exp doesn't exist anymore (weakref)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"post_run_cell: 1 f{self.exp}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReferenceError\u001b[0m: weakly-referenced object no longer exists"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.140s\n",
      "･ CPU:         0       0     2154 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cleanup\n",
    "del exp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript # prevent committing an unsaved notebook\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "323px",
    "left": "956px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
